{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19249350",
   "metadata": {},
   "source": [
    "# Dataset preparation and feature extraction\n",
    "\n",
    "Here we provide code for dataset preparation and feature extraction in our paper. Ensure that the image data is placed in the folder `./image_data`, where the bright-field image at 0h (before CHIR treatment), the cell-containing regions, and the final cTnT fluorescence images for each well should be stored at `./image_data/CD00-*/[brightfield|cell_region|ctnt]/S*.png`. The information abour cell lines should be stored in the csv file `./image_data/cell_line_info.csv`. \n",
    "\n",
    "After running the notebook (which may take a long time), the data frames (`./dataset/CD00-*.pkl`) for later analysis will be obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a744ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9bbbaf",
   "metadata": {},
   "source": [
    "## Create Data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06139b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_dir = \"./image_data/\" # you may modify it if you save the image to somewhere else\n",
    "\n",
    "batch_names = [\"CD00-%d\" % i for i in range(1, 11)]\n",
    "\n",
    "cell_line_info = pd.read_csv(os.path.join(image_data_dir, \"cell_line_info.csv\"), index_col=0)\n",
    "cell_line_info = dict(zip(cell_line_info.batch_name, cell_line_info.cell_line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d94b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./dataset\", exist_ok = True)\n",
    "\n",
    "for batch_name in batch_names:\n",
    "    \n",
    "    df = []\n",
    "    cell_line = cell_line_info[batch_name]\n",
    "    S_ids = [int(os.path.split(img_name)[1][1:4]) for img_name in glob.glob(os.path.join(image_data_dir, batch_name,  \"brightfield/*.png\"))]\n",
    "    \n",
    "    for S_id in S_ids:\n",
    "        df.append((batch_name, cell_line, S_id))\n",
    "        \n",
    "    df = pd.DataFrame(df, columns=[\"batch_name\", \"cell_line\", \"S_id\"])\n",
    "    df.to_pickle(\"./dataset/%s.pkl\" % batch_name)\n",
    "    df.to_csv(\"./dataset/%s.csv\" % batch_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d1bc72",
   "metadata": {},
   "source": [
    "## Quantify the differentiation efficiency\n",
    "\n",
    "Now we use the cTnT images to compute the Differentiation Efficiency Indexes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233cf6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch_name in batch_names:\n",
    "    \n",
    "    df = pd.read_pickle(\"./dataset/%s.pkl\" % batch_name)\n",
    "    \n",
    "    print(\"Computing \", batch_name)\n",
    "    \n",
    "    for i in tqdm.tqdm(range(len(df))):\n",
    "        \n",
    "        ctnt_dir = os.path.join(image_data_dir, batch_name, \"ctnt\", \"S%03d.png\" % df.S_id[i])\n",
    "        ctnt = cv2.imread(ctnt_dir, cv2.IMREAD_GRAYSCALE) / 255\n",
    "        \n",
    "        width0, width1 = ctnt.shape\n",
    "        differentiation_efficiency_index = ctnt[ctnt > 0.5].sum() / (width0 * width1)\n",
    "        \n",
    "        df.at[i, \"differentiation_efficiency_index\"] = differentiation_efficiency_index\n",
    "    \n",
    "    df.to_pickle(\"./dataset/%s.pkl\" % batch_name)\n",
    "    df.to_csv(\"./dataset/%s.csv\" % batch_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2319e791",
   "metadata": {},
   "source": [
    "Compute the normalized differentiation efficiency for each well. Since the differentiation efficiency vary among batches, the normalization is performed on each cell lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = dict()\n",
    "for batch_name in batch_names:\n",
    "    df = pd.read_pickle(\"./dataset/%s.pkl\" % batch_name)\n",
    "    df_dict[batch_name] = df\n",
    "    \n",
    "max_eff = dict([(cell_line, 0) for cell_line in cell_line_info.values()])\n",
    "for batch_name in batch_names:\n",
    "    df = df_dict[batch_name]\n",
    "    cell_line = cell_line_info[batch_name]  \n",
    "    max_eff[cell_line] = max(max_eff[cell_line], df.differentiation_efficiency_index.max())\n",
    "\n",
    "for batch_name in batch_names:\n",
    "    df = df_dict[batch_name]\n",
    "    cell_line = cell_line_info[batch_name]\n",
    "    df.loc[:, \"normalized_efficiency\"] = df.differentiation_efficiency_index / max_eff[cell_line]\n",
    "    df.to_pickle(\"./dataset/%s.pkl\" % batch_name)\n",
    "    df.to_csv(\"./dataset/%s.csv\" % batch_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4902f711",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "\n",
    "Then we extracted 343 features from the brightfield images and the cell region masks (which are also derived from the brightfield images). These features include:\n",
    "\n",
    "* Area, Circumference, Area/Circumference Ratio, Solidity, Convexity, Circularity, Spacing, Max Centroid-Contour Distance (CCD), Min CCD, Min/Max Ratio of CCD, Mean of CCD, Standard Deviation of CCD : these feature were computed using the cell region masks.\n",
    "\n",
    "* Total Variation, Hu Moment 1-7, SIFT 1-256, ORB 1-64: these features were computed using the brightfield images.\n",
    "\n",
    "* Local Entropy, Cell Brightness, Cell Contrast: these features were computed using both the brightfield images and the cell region masks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac0a10",
   "metadata": {},
   "source": [
    "**Note**: SIFT 1-256 and ORB 1-64 are \"bag-of-keywords\" representation computed from local feature descriptors, which requires a training phase. We have trained the two feature extractor using bright-field images (saved at `./image_data/additional_images_for_training_local_feature_extractors/*.png`, which were excluded from the dataset) and cached them in `./utils/feature_extractor_sift.pkl` and `feature_extractor_orb.pkl`, so the following code can be run directly. \n",
    "\n",
    "If you want to reproduce the training of the SIFT and ORB feature extractor yourself, you can uncomment the code in the next block and run it; otherwise simply skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### You should uncomment the following code if you want to retrain the SIFT and ORB feature extractor.\n",
    "\n",
    "# from utils.local_features import BagOfKeypointsRepresentation\n",
    "\n",
    "# brightfield_imgs = glob.glob(os.path.join(image_data_dir, \"additional_images_for_training_local_feature_extractors\", \"*.png\"))\n",
    "\n",
    "# orb = BagOfKeypointsRepresentation(\n",
    "#     random_state = 123, \n",
    "#     candidates_for_each = 50, \n",
    "#     clusters = 64, \n",
    "#     des_type=\"ORB\"\n",
    "# )\n",
    "# orb.fit(brightfield_imgs)\n",
    "# orb.save(\"./utils/feature_extractor_orb.pkl\")\n",
    "\n",
    "# sift = BagOfKeypointsRepresentation(\n",
    "#     random_state = 123, \n",
    "#     candidates_for_each = 50, \n",
    "#     clusters = 256, \n",
    "#     des_type=\"SIFT\"\n",
    "# )\n",
    "# sift.fit(brightfield_imgs)\n",
    "# sift.save(\"./utils/feature_extractor_sift.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2507d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import (\n",
    "    compute_area_circumference, \n",
    "    compute_CCD_features, \n",
    "    compute_cell_region_grayscale_feature,\n",
    "    compute_Hu_moment, \n",
    "    compute_local_features, \n",
    "    compute_solidity_convexity, \n",
    "    compute_spacing, \n",
    "    compute_total_variation\n",
    ")\n",
    "\n",
    "func_brightfield = [\n",
    "    compute_total_variation,\n",
    "    compute_Hu_moment, \n",
    "    compute_local_features, \n",
    "]\n",
    "\n",
    "func_mask = [\n",
    "    compute_area_circumference, \n",
    "    compute_solidity_convexity, \n",
    "    compute_spacing, \n",
    "    compute_CCD_features\n",
    "]\n",
    "\n",
    "func_brightfield_mask = [\n",
    "    compute_cell_region_grayscale_feature\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874f34c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch_name in batch_names:\n",
    "    \n",
    "    print(\"Computing batch %s\" % batch_name)\n",
    "    \n",
    "    df = pd.read_pickle(\"./dataset/%s.pkl\" % batch_name)\n",
    "    \n",
    "    for i in tqdm.tqdm(df.index):\n",
    "        \n",
    "        brightfield_dir = os.path.join(image_data_dir, batch_name, \"brightfield\", \"S%03d.png\" % df.S_id[i])\n",
    "        mask_dir = os.path.join(image_data_dir, batch_name, \"cell_region\", \"S%03d.png\" % df.S_id[i])\n",
    "        \n",
    "        for func in func_mask:\n",
    "            features = func(mask_dir)\n",
    "            for key, value in features.items():\n",
    "                df.at[i, key] = value\n",
    "                \n",
    "        for func in func_brightfield_mask:\n",
    "            features = func(brightfield_dir, mask_dir)\n",
    "            for key, value in features.items():\n",
    "                df.at[i, key] = value\n",
    "\n",
    "        for func in func_brightfield:\n",
    "            features = func(brightfield_dir)\n",
    "            for key, value in features.items():\n",
    "                df.at[i, key] = value\n",
    "\n",
    "    df.to_pickle(\"./dataset/%s.pkl\" % batch_name)\n",
    "    df.to_csv(\"./dataset/%s.csv\" % batch_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faa68ba",
   "metadata": {},
   "source": [
    "## Split the dataset\n",
    "\n",
    "Finally we randomly split the dataset into a training set (70%) and a test set (30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f865663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "for batch_name in [\"CD00-%d\" % i for i in [1, 3, 4, 10, 2, 6, 5, 9, 8, 7]]:\n",
    "    \n",
    "    df = pd.read_pickle(\"./dataset/%s.pkl\" % batch_name)\n",
    "\n",
    "    train_idx, test_idx = train_test_split(range(len(df)), train_size=0.7)\n",
    "    df.loc[train_idx, \"train_or_test\"] = \"Train\"\n",
    "    df.loc[test_idx, \"train_or_test\"] = \"Test\"\n",
    "    df = pd.concat([df.loc[train_idx, :], df.loc[test_idx, :]], axis = 0)\n",
    "    \n",
    "    df.to_pickle(\"./dataset/%s.pkl\" % batch_name)\n",
    "    df.to_csv(\"./dataset/%s.csv\" % batch_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
