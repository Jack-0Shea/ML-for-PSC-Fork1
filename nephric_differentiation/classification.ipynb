{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbca1dd",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "We then build a logistic regression classifier on top of the extracted features of the image patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f17e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from algutils import SIFT_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23f286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed to ensure that the results are reproducible\n",
    "\n",
    "seed = 12345\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d9468de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "df_train = pd.read_pickle(\"dataset_train.pkl\")\n",
    "df_test = pd.read_pickle(\"dataset_test.pkl\")\n",
    "\n",
    "## If you want to use our precomputed STFT features, you can replace the above statements with:\n",
    "    \n",
    "#     df_train = pd.read_pickle(\"dataset_train_with_SIFT.pkl\")\n",
    "#     df_test = pd.read_pickle(\"dataset_test_with_SIFT.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8514b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the fitted STFT feature extractor\n",
    "sift_feature_extractor = SIFT_feature(filename = \"feature_extractor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb281b4",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c85da7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "\n",
    "lr = LogisticRegression(penalty = \"l1\", solver = \"liblinear\", \n",
    "                        class_weight=\"balanced\", C = 1, max_iter=1000, \n",
    "                        verbose = 1, \n",
    "                        random_state = seed,\n",
    "                       )\n",
    "\n",
    "clf = Pipeline([('scaler', StandardScaler()), \n",
    "                ('classifier', lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb3eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the feature vectors of the training set has not been computed before, compute them now\n",
    "if \"feature_SIFT\" not in df_train:\n",
    "    \n",
    "    df_train.loc[:, \"feature_SIFT\"] = list( sift.transform(df_train[\"filedir\"]) )\n",
    "    df_train.to_csv(\"dataset_train.csv\")\n",
    "    df_train.to_pickle(\"dataset_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef73949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "# fit the classifier\n",
    "clf = clf.fit(np.stack(df_train.feature_SIFT), np.stack(df_train.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c335fd",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a849805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1457/1457 [06:13<00:00,  3.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# if the feature vectors of the test set has not been computed before, compute them now\n",
    "if \"feature_SIFT\" not in df_test:\n",
    "    \n",
    "    df_test.loc[:, \"feature_SIFT\"] = list( sift_feature_extractor.transform(df_test[\"filedir\"]) )\n",
    "    df_test.to_csv(\"dataset_test.csv\")\n",
    "    df_test.to_pickle(\"dataset_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4245828",
   "metadata": {},
   "source": [
    "Obtain the evaluation metrics in **Supplementary Fig. S15e**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc8f3bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.9910775566231984, 'Precision': 0.9902713205261477, 'Recall': 0.9891710718864298, 'F1 score': 0.9897069872471881, 'AUC': 0.9988634195451765}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "y_test = np.stack(df_test.label) # the ground truth\n",
    "y_pred = clf.predict(np.stack(df_test.feature_SIFT)) # the predicted label\n",
    "y_prob = clf.predict_proba(np.stack(df_test.feature_SIFT)) # the predicted probability for each label\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "auc = roc_auc_score(y_test, y_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "print({\n",
    "        \"Accuracy\" : acc, \n",
    "        \"Precision\" : precision, \n",
    "        \"Recall\": recall, \n",
    "        \"F1 score\": f1, \n",
    "        \"AUC\" : auc\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202fd182",
   "metadata": {},
   "source": [
    "Obtain the confusion matrix in **Supplementary Fig. S15f**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1798b45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[561   4   0]\n",
      " [  2 331   6]\n",
      " [  0   1 552]]\n"
     ]
    }
   ],
   "source": [
    "confusion_mat = confusion_matrix(y_test, y_pred, labels = [\"low\", \"optimal\", \"high\"])\n",
    "\n",
    "print(\"confusion matrix:\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a06fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
